{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tella26/ChatGPT-Training/blob/main/training/chatgpt/azure/chat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pl5R25npWBMP"
      },
      "source": [
        "# Azure chat completions example (preview)\n",
        "In this example we'll try to go over all operations needed to get chat completions working using the Azure endpoints. \\\n",
        "This example focuses on chat completions but also touches on some other operations that are also available using the API. This example is meant to be a quick way of showing simple operations and is not meant as a tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGlUnALoWBMW"
      },
      "outputs": [],
      "source": [
        "import openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtSRi5J6WBMY"
      },
      "source": [
        "## Setup\n",
        "For the following sections to work properly we first have to setup some things. Let's start with the `api_base` and `api_version`. To find your `api_base` go to https://portal.azure.com, find your resource and then under \"Resource Management\" -> \"Keys and Endpoints\" look for the \"Endpoint\" value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iI0RDRaSWBMZ"
      },
      "outputs": [],
      "source": [
        "openai.api_version = '2023-03-15-preview'\n",
        "openai.api_base = '' # Please add your endpoint here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbv30SLeWBMZ"
      },
      "source": [
        "We next have to setup the `api_type` and `api_key`. We can either get the key from the portal or we can get it through Microsoft Active Directory Authentication. Depending on this the `api_type` is either `azure` or `azure_ad`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17E8l6x8WBMa"
      },
      "source": [
        "### Setup: Portal\n",
        "Let's first look at getting the key from the portal. Go to https://portal.azure.com, find your resource and then under \"Resource Management\" -> \"Keys and Endpoints\" look for one of the \"Keys\" values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90-31K7nWBMa"
      },
      "outputs": [],
      "source": [
        "openai.api_type = 'azure'\n",
        "openai.api_key = ''  # Please add your api key here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yqj6Htx4WBMb"
      },
      "source": [
        "### (Optional) Setup: Microsoft Active Directory Authentication\n",
        "Let's now see how we can get a key via Microsoft Active Directory Authentication. Uncomment the following code if you want to use Active Directory Authentication instead of keys from the portal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQabXGTmWBMb"
      },
      "outputs": [],
      "source": [
        "# from azure.identity import DefaultAzureCredential\n",
        "\n",
        "# default_credential = DefaultAzureCredential()\n",
        "# token = default_credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
        "\n",
        "# openai.api_type = 'azure_ad'\n",
        "# openai.api_key = token.token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9B4dmHOEWBMc"
      },
      "source": [
        "## Deployments\n",
        "In this section we are going to create a deployment using the `gpt-35-turbo` model that we can then use to create chat completions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mreb6m__WBMc"
      },
      "source": [
        "### Deployments: Create manually\n",
        "Let's create a deployment using the `gpt-35-turbo` model. Go to https://portal.azure.com, find your resource and then under \"Resource Management\" -> \"Model deployments\" create a new `gpt-35-turbo` deployment. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bekNywm4WBMd"
      },
      "outputs": [],
      "source": [
        "deployment_id = \"\" # Fill in the deployment id from the portal here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkQYQrC7WBMd"
      },
      "source": [
        "### (Optional) Deployments: Create programatically\n",
        "We can also create the deployment using code. Note that you can only create one deployment per model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Xy5KMNoWBMe"
      },
      "outputs": [],
      "source": [
        "model = \"gpt-35-turbo\"\n",
        "\n",
        "# Now let's create the deployment\n",
        "print(f'Creating a new deployment with model: {model}')\n",
        "result = openai.Deployment.create(model=model, scale_settings={\"scale_type\":\"standard\"})\n",
        "deployment_id = result[\"id\"]\n",
        "print(f'Successfully created deployment with id: {deployment_id}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgI3IFWgWBMf"
      },
      "source": [
        "### (Optional) Deployments: Wait for deployment to succeed\n",
        "Now let's check the status of the newly created deployment and wait till it is succeeded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qIdU5L-WBMf"
      },
      "outputs": [],
      "source": [
        "print(f'Checking for deployment status.')\n",
        "resp = openai.Deployment.retrieve(id=deployment_id)\n",
        "status = resp[\"status\"]\n",
        "print(f'Deployment {deployment_id} has status: {status}')\n",
        "while status not in [\"succeeded\", \"failed\"]:\n",
        "    resp = openai.Deployment.retrieve(id=deployment_id)\n",
        "    status = resp[\"status\"]\n",
        "    print(f'Deployment {deployment_id} has status: {status}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBpv5GRXWBMg"
      },
      "source": [
        "### Create chat completion\n",
        "Now let's send a sample chat completion to the deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3FwRppXWBMg"
      },
      "outputs": [],
      "source": [
        "# For all possible arguments see https://platform.openai.com/docs/api-reference/chat-completions/create\n",
        "response = openai.ChatCompletion.create(\n",
        "    deployment_id=deployment_id,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Knock knock.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Who's there?\"},\n",
        "        {\"role\": \"user\", \"content\": \"Orange.\"},\n",
        "    ],\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "print(f\"{response.choices[0].message.role}: {response.choices[0].message.content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0yJu2ZaWBMh"
      },
      "source": [
        "We can also stream the response.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlQkCHdkWBMh"
      },
      "outputs": [],
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "    deployment_id=deployment_id,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Knock knock.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Who's there?\"},\n",
        "        {\"role\": \"user\", \"content\": \"Orange.\"},\n",
        "    ],\n",
        "    temperature=0,\n",
        "    stream=True\n",
        ")\n",
        "\n",
        "for chunk in response:\n",
        "    delta = chunk.choices[0].delta\n",
        "\n",
        "    if \"role\" in delta.keys():\n",
        "        print(delta.role + \": \", end=\"\", flush=True)\n",
        "    if \"content\" in delta.keys():\n",
        "        print(delta.content, end=\"\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKCWAqgyWBMi"
      },
      "source": [
        "### (Optional) Deployments: Delete\n",
        "Finally let's delete the deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xw8408-rWBMj"
      },
      "outputs": [],
      "source": [
        "print(f'Deleting deployment: {deployment_id}')\n",
        "openai.Deployment.delete(sid=deployment_id)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}